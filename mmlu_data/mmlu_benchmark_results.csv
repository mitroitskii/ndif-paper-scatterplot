,table_id,row_id,rank,method,mlmodel,method_short,method_details,mlmodel_short,mlmodeldetails,evaluation_date,metrics,raw_metrics,uses_additional_data,paper,external_source_url,tags,reports
0,15219,113523,1,Gemini Ultra ~1760B,{},Gemini Ultra ~1760B,,,,2023-12-19,{'Average (%)': '90'},{'Average (%)': 90.0},False,"{'id': 1346190, 'title': 'Gemini: A Family of Highly Capable Multimodal Models', 'url': '/paper/gemini-a-family-of-highly-capable-multimodal-1', 'published': '2023-12-19T00:00:00.000000', 'code': False, 'review_url': None}",,"[{'id': 567, 'name': 'self-consistency', 'color': '#c4a000'}, {'id': 318, 'name': 'chain-of-thought', 'color': '#eea320'}]",[]
1,15219,122102,2,GPT-4o,{},GPT-4o,,,,2023-05-17,{'Average (%)': '88.7'},{'Average (%)': 88.7},False,"{'id': 1174373, 'title': 'GPT-4 Technical Report', 'url': '/paper/gpt-4-technical-report-1', 'published': '2023-03-15T00:00:00.000000', 'code': True, 'review_url': None}",,[],[]
2,15219,127848,3,Llama 3.1 405B (CoT),{},Llama 3.1 405B ,CoT,,,2024-07-31,{'Average (%)': '88.6'},{'Average (%)': 88.6},False,"{'id': 1493137, 'title': 'The Llama 3 Herd of Models', 'url': '/paper/the-llama-3-herd-of-models', 'published': '2024-07-31T00:00:00.000000', 'code': True, 'review_url': None}",,"[{'id': 318, 'name': 'chain-of-thought', 'color': '#eea320'}]",[]
3,15219,99170,4,"Claude 3 Opus (5-shot, CoT)",{},Claude 3 Opus ,"5-shot, CoT",,,2024-03-04,{'Average (%)': '88.2'},{'Average (%)': 88.2},False,"{'id': 1391602, 'title': 'The Claude 3 Model Family: Opus, Sonnet, Haiku', 'url': '/paper/the-claude-3-model-family-opus-sonnet-haiku', 'published': '2024-03-04T00:00:00.000000', 'code': False, 'review_url': None}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
4,15219,118652,5,Claude 3 Opus (5-shot),{},Claude 3 Opus ,5-shot,,,2024-03-04,{'Average (%)': '86.8'},{'Average (%)': 86.8},False,"{'id': 1391602, 'title': 'The Claude 3 Model Family: Opus, Sonnet, Haiku', 'url': '/paper/the-claude-3-model-family-opus-sonnet-haiku', 'published': '2024-03-04T00:00:00.000000', 'code': False, 'review_url': None}",,[],[]
5,15219,121578,6,Leeroo (5-shot),{},Leeroo ,5-shot,,,2024-01-25,{'Average (%)': '86.64'},{'Average (%)': 86.64},False,"{'id': 1366435, 'title': 'Routoo: Learning to Route to Large Language Models Effectively', 'url': '/paper/leeroo-orchestrator-elevating-llms', 'published': '2024-01-25T00:00:00.000000', 'code': True, 'review_url': '/paper/leeroo-orchestrator-elevating-llms/review/?hl=121578'}",,[],[]
6,15219,114904,7,GPT-4 (few-shot),{},GPT-4 ,few-shot,,,2023-03-15,{'Average (%)': '86.4'},{'Average (%)': 86.4},False,"{'id': 1174373, 'title': 'GPT-4 Technical Report', 'url': '/paper/gpt-4-technical-report-1', 'published': '2023-03-15T00:00:00.000000', 'code': True, 'review_url': '/paper/gpt-4-technical-report-1/review/?hl=114904'}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
7,15219,127849,8,Llama 3.1 70B (CoT),{},Llama 3.1 70B ,CoT,,,2024-07-31,{'Average (%)': '86.0'},{'Average (%)': 86.0},False,"{'id': 1493137, 'title': 'The Llama 3 Herd of Models', 'url': '/paper/the-llama-3-herd-of-models', 'published': '2024-07-31T00:00:00.000000', 'code': True, 'review_url': None}",,"[{'id': 318, 'name': 'chain-of-thought', 'color': '#eea320'}]",[]
8,15219,113522,9,Gemini Ultra (5-shot),{},Gemini Ultra ,5-shot,,,,{'Average (%)': '83.7'},{'Average (%)': 83.7},False,"{'id': None, 'title': None, 'url': None, 'published': None, 'code': False, 'review_url': None}",,"[{'id': 238, 'name': '5-shot', 'color': '#d08216'}]",[]
9,15219,123748,10,GaC(Qwen2-72B-Instruct + Llama-3-70B-Instruct),{},GaC,Qwen2-72B-Instruct + Llama-3-70B-Instruct,,,2024-06-18,{'Average (%)': '83.54'},{'Average (%)': 83.54},False,"{'id': 1463808, 'title': 'Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling', 'url': '/paper/breaking-the-ceiling-of-the-llm-community-by', 'published': '2024-06-18T00:00:00.000000', 'code': True, 'review_url': '/paper/breaking-the-ceiling-of-the-llm-community-by/review/?hl=123748'}",,"[{'id': 284, 'name': 'Ensemble', 'color': '#77bb41'}]",[]
10,15219,120070,11,"Claude 3 Sonnet (5-shot, CoT)",{},Claude 3 Sonnet ,"5-shot, CoT",,,2024-03-04,{'Average (%)': '81.5'},{'Average (%)': 81.5},False,"{'id': 1391602, 'title': 'The Claude 3 Model Family: Opus, Sonnet, Haiku', 'url': '/paper/the-claude-3-model-family-opus-sonnet-haiku', 'published': '2024-03-04T00:00:00.000000', 'code': False, 'review_url': None}",,[],[]
11,15219,118934,12,Flan-PaLM 2-L,{},Flan-PaLM 2-L,,,,2023-05-17,{'Average (%)': '81.2'},{'Average (%)': 81.2},False,"{'id': 1210556, 'title': 'PaLM 2 Technical Report', 'url': '/paper/palm-2-technical-report-1', 'published': '2023-05-17T00:00:00.000000', 'code': True, 'review_url': '/paper/palm-2-technical-report-1/review/?hl=118934'}",,[],[]
12,15219,113521,13,Gemini Pro (CoT@8),{},Gemini Pro ,CoT@8,,,,{'Average (%)': '79.1'},{'Average (%)': 79.1},False,"{'id': None, 'title': None, 'url': None, 'published': None, 'code': False, 'review_url': None}",,"[{'id': 318, 'name': 'chain-of-thought', 'color': '#eea320'}]",[]
13,15219,120069,14,Claude 3 Sonnet (5-shot),{},Claude 3 Sonnet ,5-shot,,,2024-03-04,{'Average (%)': '79'},{'Average (%)': 79.0},False,"{'id': 1391602, 'title': 'The Claude 3 Model Family: Opus, Sonnet, Haiku', 'url': '/paper/the-claude-3-model-family-opus-sonnet-haiku', 'published': '2024-03-04T00:00:00.000000', 'code': False, 'review_url': None}",,[],[]
14,15219,117489,15,Claude 2 (5-shot),{},Claude 2 ,5-shot,,,2023-07-11,{'Average (%)': '78.5'},{'Average (%)': 78.5},False,"{'id': 1300010, 'title': 'Model Card and Evaluations for Claude Models', 'url': '/paper/model-card-and-evaluations-for-claude-models', 'published': '2023-07-11T00:00:00.000000', 'code': False, 'review_url': None}",,"[{'id': 238, 'name': '5-shot', 'color': '#d08216'}, {'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
15,15219,118932,16,PaLM 2-L (5-shot),{},PaLM 2-L ,5-shot,,,2023-05-17,{'Average (%)': '78.3'},{'Average (%)': 78.3},False,"{'id': 1210556, 'title': 'PaLM 2 Technical Report', 'url': '/paper/palm-2-technical-report-1', 'published': '2023-05-17T00:00:00.000000', 'code': True, 'review_url': '/paper/palm-2-technical-report-1/review/?hl=118932'}",,"[{'id': 238, 'name': '5-shot', 'color': '#d08216'}]",[]
16,15219,119156,17,Qwen1.5 72B (5-shot),{},Qwen1.5 72B ,5-shot,,,2024-02-04,{'Average (%)': '77.5'},{'Average (%)': 77.5},False,"{'id': None, 'title': None, 'url': None, 'published': None, 'code': False, 'review_url': None}",,[],[]
17,15219,117488,18,Claude 1.3 (5-shot),{},Claude 1.3 ,5-shot,,,2023-04-18,{'Average (%)': '77'},{'Average (%)': 77.0},False,"{'id': 1300010, 'title': 'Model Card and Evaluations for Claude Models', 'url': '/paper/model-card-and-evaluations-for-claude-models', 'published': '2023-07-11T00:00:00.000000', 'code': False, 'review_url': None}",,"[{'id': 238, 'name': '5-shot', 'color': '#d08216'}, {'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
18,15219,120072,19,"Claude 3 Haiku (5-shot, CoT)",{},Claude 3 Haiku ,"5-shot, CoT",,,2024-03-04,{'Average (%)': '76.7'},{'Average (%)': 76.7},False,"{'id': 1391602, 'title': 'The Claude 3 Model Family: Opus, Sonnet, Haiku', 'url': '/paper/the-claude-3-model-family-opus-sonnet-haiku', 'published': '2024-03-04T00:00:00.000000', 'code': False, 'review_url': None}",,[],[]
19,15219,115961,20,Leeroo (5-shot),{},Leeroo ,5-shot,,,2024-01-25,{'Average (%)': '75.9'},{'Average (%)': 75.9},False,"{'id': 1366435, 'title': 'Routoo: Learning to Route to Large Language Models Effectively', 'url': '/paper/leeroo-orchestrator-elevating-llms', 'published': '2024-01-25T00:00:00.000000', 'code': True, 'review_url': '/paper/leeroo-orchestrator-elevating-llms/review/?hl=115961'}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
20,15219,119092,21,Camelidae-8×34B (5-shot),{},Camelidae-8×34B ,5-shot,,,2024-01-05,{'Average (%)': '75.6'},{'Average (%)': 75.6},False,"{'id': 1355944, 'title': 'Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks', 'url': '/paper/parameter-efficient-sparsity-crafting-from', 'published': '2024-01-05T00:00:00.000000', 'code': True, 'review_url': '/paper/parameter-efficient-sparsity-crafting-from/review/?hl=119092'}",,"[{'id': 238, 'name': '5-shot', 'color': '#d08216'}]",[]
21,15219,120071,22,Claude 3 Haiku (5-shot),{},Claude 3 Haiku ,5-shot,,,2024-03-04,{'Average (%)': '75.2'},{'Average (%)': 75.2},False,"{'id': 1391602, 'title': 'The Claude 3 Model Family: Opus, Sonnet, Haiku', 'url': '/paper/the-claude-3-model-family-opus-sonnet-haiku', 'published': '2024-03-04T00:00:00.000000', 'code': False, 'review_url': None}",,[],[]
22,15219,73150,23,Flan-U-PaLM 540B,{},Flan-U-PaLM 540B,,,,2022-10-20,{'Average (%)': '74.1'},{'Average (%)': 74.1},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=73150'}",,"[{'id': 184, 'name': 'fine-tuned', 'color': '#e56666'}]",[]
23,15219,119889,24,DBRX Instruct 132B (5-shot),{},DBRX Instruct 132B ,5-shot,,,2024-07-31,{'Average (%)': '73.7'},{'Average (%)': 73.7},False,"{'id': 1493137, 'title': 'The Llama 3 Herd of Models', 'url': '/paper/the-llama-3-herd-of-models', 'published': '2024-07-31T00:00:00.000000', 'code': True, 'review_url': None}",,[],[]
24,15219,73148,25,Flan-PaLM 540B,{},Flan-PaLM 540B,,,,2022-10-20,{'Average (%)': '73.5'},{'Average (%)': 73.5},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=73148'}",,"[{'id': 184, 'name': 'fine-tuned', 'color': '#e56666'}]",[]
25,15219,107031,26,Claude Instant 1.1 (5-shot),{},Claude Instant 1.1 ,5-shot,,,2023-07-11,{'Average (%)': '73.4'},{'Average (%)': 73.4},False,"{'id': 1300010, 'title': 'Model Card and Evaluations for Claude Models', 'url': '/paper/model-card-and-evaluations-for-claude-models', 'published': '2023-07-11T00:00:00.000000', 'code': False, 'review_url': None}",,"[{'id': 238, 'name': '5-shot', 'color': '#d08216'}, {'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
26,15219,127850,27,Llama 3.1 8B (CoT),{},Llama 3.1 8B ,CoT,,,2024-07-31,{'Average (%)': '73.0'},{'Average (%)': 73.0},False,"{'id': 1493137, 'title': 'The Llama 3 Herd of Models', 'url': '/paper/the-llama-3-herd-of-models', 'published': '2024-07-31T00:00:00.000000', 'code': True, 'review_url': None}",,"[{'id': 318, 'name': 'chain-of-thought', 'color': '#eea320'}]",[]
27,15219,72866,28,"Flan-PaLM (5-shot, finetuned)",{},Flan-PaLM ,"5-shot, finetuned",,,2024-07-31,{'Average (%)': '72.2'},{'Average (%)': 72.2},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=72866'}",,"[{'id': 238, 'name': '5-shot', 'color': '#d08216'}, {'id': 184, 'name': 'fine-tuned', 'color': '#e56666'}]",[]
28,15219,96120,29,code-davinci-002 175B + REPLUG LSR (5-shot),{},code-davinci-002 175B + REPLUG LSR ,5-shot,,,2023-01-30,{'Average (%)': '71.8'},{'Average (%)': 71.8},False,"{'id': 1149330, 'title': 'REPLUG: Retrieval-Augmented Black-Box Language Models', 'url': '/paper/replug-retrieval-augmented-black-box-language', 'published': '2023-01-30T00:00:00.000000', 'code': True, 'review_url': None}",,"[{'id': 238, 'name': '5-shot', 'color': '#d08216'}, {'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
29,15219,113520,30,Gemini Pro (5-shot),{},Gemini Pro ,5-shot,,,,{'Average (%)': '71.8'},{'Average (%)': 71.8},False,"{'id': None, 'title': None, 'url': None, 'published': None, 'code': False, 'review_url': None}",,"[{'id': 238, 'name': '5-shot', 'color': '#d08216'}, {'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
30,15219,73159,31,Flan-PaLM 540B (CoT),{},Flan-PaLM 540B ,CoT,,,2022-10-20,{'Average (%)': '70.9'},{'Average (%)': 70.9},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=73159'}",,"[{'id': 318, 'name': 'chain-of-thought', 'color': '#eea320'}, {'id': 184, 'name': 'fine-tuned', 'color': '#e56666'}]",[]
31,15219,72741,32,U-PaLM 540B (5-shot),{},U-PaLM 540B ,5-shot,,,2022-10-20,{'Average (%)': '70.7'},{'Average (%)': 70.7},False,"{'id': 1097009, 'title': 'Transcending Scaling Laws with 0.1% Extra Compute', 'url': '/paper/transcending-scaling-laws-with-0-1-extra', 'published': '2022-10-20T00:00:00.000000', 'code': False, 'review_url': '/paper/transcending-scaling-laws-with-0-1-extra/review/?hl=72741'}",,"[{'id': 238, 'name': '5-shot', 'color': '#d08216'}, {'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
32,15219,114901,33,Falcon 180B (5-shot),{},Falcon 180B ,5-shot,,,2023-11-28,{'Average (%)': '70.6'},{'Average (%)': 70.6},False,"{'id': 1329402, 'title': 'The Falcon Series of Open Language Models', 'url': '/paper/the-falcon-series-of-open-language-models', 'published': '2023-11-28T00:00:00.000000', 'code': False, 'review_url': '/paper/the-falcon-series-of-open-language-models/review/?hl=114901'}",,"[{'id': 238, 'name': '5-shot', 'color': '#d08216'}, {'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
33,15219,118948,34,Mixtral 8x7B (5-shot),{},Mixtral 8x7B ,5-shot,,,2024-01-08,{'Average (%)': '70.6'},{'Average (%)': 70.6},False,"{'id': 1356260, 'title': 'Mixtral of Experts', 'url': '/paper/mixtral-of-experts', 'published': '2024-01-08T00:00:00.000000', 'code': True, 'review_url': None}",,"[{'id': 238, 'name': '5-shot', 'color': '#d08216'}]",[]
34,15219,73151,35,"Flan-PaLM (5-shot, finetuned, CoT)",{},Flan-PaLM ,"5-shot, finetuned, CoT",,,2022-10-20,{'Average (%)': '70.2'},{'Average (%)': 70.2},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=73151'}",,"[{'id': 318, 'name': 'chain-of-thought', 'color': '#eea320'}, {'id': 238, 'name': '5-shot', 'color': '#d08216'}, {'id': 184, 'name': 'fine-tuned', 'color': '#e56666'}]",[]
35,15219,114905,36,GPT-3.5 Turbo,{},GPT-3.5 Turbo,,,,2023-03-15,{'Average (%)': '70.0'},{'Average (%)': 70.0},False,"{'id': 1174373, 'title': 'GPT-4 Technical Report', 'url': '/paper/gpt-4-technical-report-1', 'published': '2023-03-15T00:00:00.000000', 'code': True, 'review_url': '/paper/gpt-4-technical-report-1/review/?hl=114905'}",,[],[]
36,15219,73161,37,Flan-U-PaLM 540B (CoT),{},Flan-U-PaLM 540B ,CoT,,,2022-10-20,{'Average (%)': '69.8'},{'Average (%)': 69.8},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=73161'}",,"[{'id': 318, 'name': 'chain-of-thought', 'color': '#eea320'}, {'id': 184, 'name': 'fine-tuned', 'color': '#e56666'}]",[]
37,15219,58550,38,PaLM,{},PaLM,,,,2022-04-05,{'Average (%)': '69.3'},{'Average (%)': 69.3},False,"{'id': 989558, 'title': 'PaLM: Scaling Language Modeling with Pathways', 'url': '/paper/palm-scaling-language-modeling-with-pathways-1', 'published': '2022-04-05T00:00:00.000000', 'code': True, 'review_url': None}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
38,15219,105221,39,AiLMe (5-shot),{},AiLMe ,5-shot,,,2023-06-23,{'Average (%)': '69.0'},{'Average (%)': 69.0},False,"{'id': None, 'title': None, 'url': None, 'published': None, 'code': False, 'review_url': None}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
39,15219,97685,40,LLaMA 65B (fine-tuned),{},LLaMA 65B ,fine-tuned,,,2023-02-27,{'Average (%)': '68.9'},{'Average (%)': 68.9},True,"{'id': 1164350, 'title': 'LLaMA: Open and Efficient Foundation Language Models', 'url': '/paper/llama-open-and-efficient-foundation-language-1', 'published': '2023-02-27T00:00:00.000000', 'code': True, 'review_url': '/paper/llama-open-and-efficient-foundation-language-1/review/?hl=97685'}",,"[{'id': 184, 'name': 'fine-tuned', 'color': '#e56666'}]",[]
40,15219,96121,41,code-davinci-002 175B (5-shot),{},code-davinci-002 175B ,5-shot,,,2023-01-30,{'Average (%)': '68.3'},{'Average (%)': 68.3},False,"{'id': 1149330, 'title': 'REPLUG: Retrieval-Augmented Black-Box Language Models', 'url': '/paper/replug-retrieval-augmented-black-box-language', 'published': '2023-01-30T00:00:00.000000', 'code': True, 'review_url': None}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
41,15219,118813,42,code-davinci-002 175B (5-shot),{},code-davinci-002 175B ,5-shot,,,2022-10-20,{'Average (%)': '68.2'},{'Average (%)': 68.2},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=118813'}",,[],[]
42,15219,50746,43,Chinchilla 70B (5-shot),{},Chinchilla 70B ,5-shot,,,2022-03-29,{'Average (%)': '67.5'},{'Average (%)': 67.5},False,"{'id': 985465, 'title': 'Training Compute-Optimal Large Language Models', 'url': '/paper/training-compute-optimal-large-language', 'published': '2022-03-29T00:00:00.000000', 'code': True, 'review_url': None}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
43,15219,119093,44,Qwen2idae-16x14B (5-shot),{},Qwen2idae-16x14B ,5-shot,,,2024-03-12,{'Average (%)': '66.7'},{'Average (%)': 66.7},False,"{'id': 1355944, 'title': 'Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks', 'url': '/paper/parameter-efficient-sparsity-crafting-from', 'published': '2024-01-05T00:00:00.000000', 'code': True, 'review_url': '/paper/parameter-efficient-sparsity-crafting-from/review/?hl=119093'}",,[],[]
44,15219,73149,45,Flan-cont-PaLM 62B,{},Flan-cont-PaLM 62B,,,,2022-10-20,{'Average (%)': '66.1'},{'Average (%)': 66.1},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=73149'}",,[],[]
45,15219,118811,46,text-davinci-003 175B (5-shot),{},text-davinci-003 175B ,5-shot,,,2022-10-20,{'Average (%)': '64.8'},{'Average (%)': 64.8},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=118811'}",,[],[]
46,15219,118812,47,text-davinci-003 175B (CoT),{},text-davinci-003 175B ,CoT,,,2022-10-20,{'Average (%)': '64.6'},{'Average (%)': 64.6},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=118812'}",,[],[]
47,15219,118820,48,code-davinci-002 175B (CoT),{},code-davinci-002 175B ,CoT,,,2022-10-20,{'Average (%)': '64.5'},{'Average (%)': 64.5},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=118820'}",,[],[]
48,15219,97684,49,LLaMA 65B (5-shot),{},LLaMA 65B ,5-shot,,,2023-02-27,{'Average (%)': '63.4'},{'Average (%)': 63.4},True,"{'id': 1164350, 'title': 'LLaMA: Open and Efficient Foundation Language Models', 'url': '/paper/llama-open-and-efficient-foundation-language-1', 'published': '2023-02-27T00:00:00.000000', 'code': True, 'review_url': '/paper/llama-open-and-efficient-foundation-language-1/review/?hl=97684'}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
49,15219,118809,50,text-davinci-002 175B (5-shot),{},text-davinci-002 175B ,5-shot,,,2022-10-20,{'Average (%)': '63.1'},{'Average (%)': 63.1},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=118809'}",,[],[]
50,15219,106299,51,LLaMA 2 34B (5-shot),{},LLaMA 2 34B ,5-shot,,,2023-07-18,{'Average (%)': '62.6'},{'Average (%)': 62.6},True,"{'id': 1248363, 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models', 'url': '/paper/llama-2-open-foundation-and-fine-tuned-chat', 'published': '2023-07-18T00:00:00.000000', 'code': True, 'review_url': '/paper/llama-2-open-foundation-and-fine-tuned-chat/review/?hl=106299'}",,[],[]
51,15219,118947,52,Mistral 7B (5-shot),{},Mistral 7B ,5-shot,,,2024-01-08,{'Average (%)': '62.5'},{'Average (%)': 62.5},False,"{'id': 1356260, 'title': 'Mixtral of Experts', 'url': '/paper/mixtral-of-experts', 'published': '2024-01-08T00:00:00.000000', 'code': True, 'review_url': None}",,[],[]
52,15219,118805,53,Flan-cont-PaLM 62B (CoT),{},Flan-cont-PaLM 62B ,CoT,,,2022-10-20,{'Average (%)': '62'},{'Average (%)': 62.0},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=118805'}",,[],[]
53,15219,118935,54,Mistral 7B (5-shot),{},Mistral 7B ,5-shot,,,2023-10-10,{'Average (%)': '60.1'},{'Average (%)': 60.1},False,"{'id': 1297015, 'title': 'Mistral 7B', 'url': '/paper/mistral-7b', 'published': '2023-10-10T00:00:00.000000', 'code': True, 'review_url': '/paper/mistral-7b/review/?hl=118935'}",,[],[]
54,15219,47494,55,Gopher 280B (5-shot),{},Gopher 280B ,5-shot,,,2021-12-08,{'Average (%)': '60.0'},{'Average (%)': 60.0},False,"{'id': 942590, 'title': 'Scaling Language Models: Methods, Analysis & Insights from Training Gopher', 'url': '/paper/scaling-language-models-methods-analysis-1', 'published': '2021-12-08T00:00:00.000000', 'code': True, 'review_url': None}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
55,15219,118810,56,text-davinci-002 175B (CoT),{},text-davinci-002 175B ,CoT,,,2022-10-20,{'Average (%)': '60'},{'Average (%)': 60.0},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=118810'}",,[],[]
56,15219,118808,57,GPT-3 Davinci 175B (CoT),{},GPT-3 Davinci 175B ,CoT,,,2022-10-20,{'Average (%)': '59.5'},{'Average (%)': 59.5},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=118808'}",,[],[]
57,15219,117237,58,LLaMA 33B (5-shot),{},LLaMA 33B ,5-shot,,,2023-02-27,{'Average (%)': '57.8'},{'Average (%)': 57.8},True,"{'id': 1164350, 'title': 'LLaMA: Open and Efficient Foundation Language Models', 'url': '/paper/llama-open-and-efficient-foundation-language-1', 'published': '2023-02-27T00:00:00.000000', 'code': True, 'review_url': '/paper/llama-open-and-efficient-foundation-language-1/review/?hl=117237'}",,[],[]
58,15219,114903,59,Falcon 40B,{},Falcon 40B,,,,2023-11-28,{'Average (%)': '57.0'},{'Average (%)': 57.0},False,"{'id': 1329402, 'title': 'The Falcon Series of Open Language Models', 'url': '/paper/the-falcon-series-of-open-language-models', 'published': '2023-11-28T00:00:00.000000', 'code': False, 'review_url': '/paper/the-falcon-series-of-open-language-models/review/?hl=114903'}",,[],[]
59,15219,73147,60,Flan-PaLM,{},Flan-PaLM,,,,2022-10-20,{'Average (%)': '56.9'},{'Average (%)': 56.9},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=73147'}",,[],[]
60,15219,107030,61,Qwen 7B (5-shot),{},Qwen 7B ,5-shot,,,2023-08-03,{'Average (%)': '56.7'},{'Average (%)': 56.7},False,"{'id': None, 'title': None, 'url': None, 'published': None, 'code': False, 'review_url': None}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
61,15219,118378,62,FLAN-UL2 20B (5-shot),{},FLAN-UL2 20B ,5-shot,,,2022-05-10,{'Average (%)': '55.7'},{'Average (%)': 55.7},False,"{'id': 1007751, 'title': 'UL2: Unifying Language Learning Paradigms', 'url': '/paper/unifying-language-learning-paradigms', 'published': '2022-05-10T00:00:00.000000', 'code': True, 'review_url': '/paper/unifying-language-learning-paradigms/review/?hl=118378'}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
62,15219,73141,63,Flan-T5-XXL 11B,{},Flan-T5-XXL 11B,,,,2022-10-20,{'Average (%)': '55.1'},{'Average (%)': 55.1},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=73141'}",,[],[]
63,15219,106287,64,LLaMA 2 13B (5-shot),{},LLaMA 2 13B ,5-shot,,,2023-07-18,{'Average (%)': '54.8'},{'Average (%)': 54.8},True,"{'id': 1248363, 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models', 'url': '/paper/llama-2-open-foundation-and-fine-tuned-chat', 'published': '2023-07-18T00:00:00.000000', 'code': True, 'review_url': '/paper/llama-2-open-foundation-and-fine-tuned-chat/review/?hl=106287'}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
64,15219,119030,65,Branch-Train-MiX 4x7B (sampling top-1 experts),{},Branch-Train-MiX 4x7B ,sampling top-1 experts,,,2024-03-12,{'Average (%)': '53.2'},{'Average (%)': 53.2},False,"{'id': 1397263, 'title': 'Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM', 'url': '/paper/branch-train-mix-mixing-expert-llms-into-a', 'published': '2024-03-12T00:00:00.000000', 'code': True, 'review_url': None}",,[],[]
65,15219,85951,66,GAL 120B (zero-shot),{},GAL 120B ,zero-shot,,,2022-11-16,{'Average (%)': '52.6'},{'Average (%)': 52.6},False,"{'id': 1112728, 'title': 'Galactica: A Large Language Model for Science', 'url': '/paper/galactica-a-large-language-model-for-science-1', 'published': '2022-11-16T00:00:00.000000', 'code': True, 'review_url': '/paper/galactica-a-large-language-model-for-science-1/review/?hl=85951'}",,"[{'id': 188, 'name': 'zero-shot', 'color': '#2771D3'}, {'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
66,15219,73140,67,Flan-T5-XL 3B,{},Flan-T5-XL 3B,,,,2022-10-20,{'Average (%)': '52.4'},{'Average (%)': 52.4},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=73140'}",,[],[]
67,15219,118379,68,FLAN-UL2 20B (chain-of-thought),{},FLAN-UL2 20B ,chain-of-thought,,,2022-05-10,{'Average (%)': '52.2'},{'Average (%)': 52.2},False,"{'id': 1007751, 'title': 'UL2: Unifying Language Learning Paradigms', 'url': '/paper/unifying-language-learning-paradigms', 'published': '2022-05-10T00:00:00.000000', 'code': True, 'review_url': '/paper/unifying-language-learning-paradigms/review/?hl=118379'}",,"[{'id': 318, 'name': 'chain-of-thought', 'color': '#eea320'}]",[]
68,15219,73146,69,Flan-PaLM 8B,{},Flan-PaLM 8B,,,,2022-10-20,{'Average (%)': '49.3'},{'Average (%)': 49.3},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=73146'}",,[],[]
69,15219,47497,70,UnifiedQA 11B,{},UnifiedQA 11B,,,,2020-05-02,{'Average (%)': '48.9'},{'Average (%)': 48.9},False,"{'id': 193599, 'title': 'UnifiedQA: Crossing Format Boundaries With a Single QA System', 'url': '/paper/unifiedqa-crossing-format-boundaries-with-a', 'published': '2020-05-02T00:00:00.000000', 'code': True, 'review_url': '/paper/unifiedqa-crossing-format-boundaries-with-a/review/?hl=47497'}",,"[{'id': 184, 'name': 'fine-tuned', 'color': '#e56666'}]",[]
70,15219,73156,71,Flan-T5-XXL 11B (CoT),{},Flan-T5-XXL 11B ,CoT,,,2022-10-20,{'Average (%)': '48.6'},{'Average (%)': 48.6},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=73156'}",,"[{'id': 318, 'name': 'chain-of-thought', 'color': '#eea320'}]",[]
71,15219,66197,72,Atlas (5-shot),{},Atlas ,5-shot,,,2022-08-05,{'Average (%)': '47.9'},{'Average (%)': 47.9},False,"{'id': 1055376, 'title': 'Atlas: Few-shot Learning with Retrieval Augmented Language Models', 'url': '/paper/few-shot-learning-with-retrieval-augmented', 'published': '2022-08-05T00:00:00.000000', 'code': True, 'review_url': '/paper/few-shot-learning-with-retrieval-augmented/review/?hl=66197'}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
72,15219,73155,73,Flan-T5-XL 3B (CoT),{},Flan-T5-XL 3B ,CoT,,,2022-10-20,{'Average (%)': '45.5'},{'Average (%)': 45.5},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=73155'}",,"[{'id': 318, 'name': 'chain-of-thought', 'color': '#eea320'}]",[]
73,15219,106297,74,LLaMA 2 7B (5-shot),{},LLaMA 2 7B ,5-shot,,,2023-07-18,{'Average (%)': '45.3'},{'Average (%)': 45.3},True,"{'id': 1248363, 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models', 'url': '/paper/llama-2-open-foundation-and-fine-tuned-chat', 'published': '2023-07-18T00:00:00.000000', 'code': True, 'review_url': '/paper/llama-2-open-foundation-and-fine-tuned-chat/review/?hl=106297'}",,[],[]
74,15219,73129,75,Flan-T5-Large 780M,{},Flan-T5-Large 780M,,,,2022-10-20,{'Average (%)': '45.1'},{'Average (%)': 45.1},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=73129'}",,[],[]
75,15219,88975,76,GLM-130B,{},GLM-130B,,,,2022-10-05,{'Average (%)': '44.8'},{'Average (%)': 44.8},False,"{'id': 1086925, 'title': 'GLM-130B: An Open Bilingual Pre-trained Model', 'url': '/paper/glm-130b-an-open-bilingual-pre-trained-model', 'published': '2022-10-05T00:00:00.000000', 'code': True, 'review_url': '/paper/glm-130b-an-open-bilingual-pre-trained-model/review/?hl=88975'}",,[],[]
76,15219,47496,77,GPT-3 175B (5-shot),{},GPT-3 175B ,5-shot,,,2020-06-11,{'Average (%)': '43.9'},{'Average (%)': 43.9},False,"{'id': 216419, 'title': 'Measuring Massive Multitask Language Understanding', 'url': '/paper/measuring-massive-multitask-language', 'published': '2020-09-07T00:00:00.000000', 'code': True, 'review_url': '/paper/measuring-massive-multitask-language/review/?hl=47496'}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
77,15219,47498,78,GPT-3 175B (fine-tuned),{},GPT-3 175B ,fine-tuned,,,2020-09-07,{'Average (%)': '43.9'},{'Average (%)': 43.9},False,"{'id': 216419, 'title': 'Measuring Massive Multitask Language Understanding', 'url': '/paper/measuring-massive-multitask-language', 'published': '2020-09-07T00:00:00.000000', 'code': True, 'review_url': '/paper/measuring-massive-multitask-language/review/?hl=47498'}",,"[{'id': 184, 'name': 'fine-tuned', 'color': '#e56666'}]",[]
78,15219,117923,79,GPT-3 175B (5-shot),{},GPT-3 175B ,5-shot,,,2020-05-28,{'Average (%)': '43.9'},{'Average (%)': 43.9},False,"{'id': 198147, 'title': 'Language Models are Few-Shot Learners', 'url': '/paper/language-models-are-few-shot-learners', 'published': '2020-05-28T00:00:00.000000', 'code': True, 'review_url': '/paper/language-models-are-few-shot-learners/review/?hl=117923'}",,[],[]
79,15219,47499,80,GPT-3 6.7B (fine-tuned),{},GPT-3 6.7B ,fine-tuned,,,2020-09-07,{'Average (%)': '43.2'},{'Average (%)': 43.2},False,"{'id': 216419, 'title': 'Measuring Massive Multitask Language Understanding', 'url': '/paper/measuring-massive-multitask-language', 'published': '2020-09-07T00:00:00.000000', 'code': True, 'review_url': '/paper/measuring-massive-multitask-language/review/?hl=47499'}",,"[{'id': 184, 'name': 'fine-tuned', 'color': '#e56666'}]",[]
80,15219,126691,81,Gemma 2B,{},Gemma 2B,,,,2024-07-31,{'Average (%)': '42.3'},{'Average (%)': 42.3},False,"{'id': None, 'title': None, 'url': None, 'published': None, 'code': False, 'review_url': None}",,[],[]
81,15219,73154,82,Flan-T5-Large 780M (CoT),{},Flan-T5-Large 780M ,CoT,,,2022-10-20,{'Average (%)': '40.5'},{'Average (%)': 40.5},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=73154'}",,[],[]
82,15219,118807,83,GPT-3 Davinci 175B (5-shot),{},GPT-3 Davinci 175B ,5-shot,,,2022-10-20,{'Average (%)': '39.7'},{'Average (%)': 39.7},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=118807'}",,[],[]
83,15219,100780,84,Bloomberg GPT 50B (5-shot),{},Bloomberg GPT 50B ,5-shot,,,2023-03-30,{'Average (%)': '39.2'},{'Average (%)': 39.2},False,"{'id': 1183339, 'title': 'BloombergGPT: A Large Language Model for Finance', 'url': '/paper/bloomberggpt-a-large-language-model-for', 'published': '2023-03-30T00:00:00.000000', 'code': False, 'review_url': '/paper/bloomberggpt-a-large-language-model-for/review/?hl=100780'}",,[],[]
84,15219,118377,85,UL2 20B (5-shot),{},UL2 20B ,5-shot,,,2022-05-10,{'Average (%)': '39.2'},{'Average (%)': 39.2},False,"{'id': 1007751, 'title': 'UL2: Unifying Language Learning Paradigms', 'url': '/paper/unifying-language-learning-paradigms', 'published': '2022-05-10T00:00:00.000000', 'code': True, 'review_url': '/paper/unifying-language-learning-paradigms/review/?hl=118377'}",,[],[]
85,15219,100783,86,BLOOM 176B (5-shot),{},BLOOM 176B ,5-shot,,,2023-03-30,{'Average (%)': '39.1'},{'Average (%)': 39.1},False,"{'id': 1183339, 'title': 'BloombergGPT: A Large Language Model for Finance', 'url': '/paper/bloomberggpt-a-large-language-model-for', 'published': '2023-03-30T00:00:00.000000', 'code': False, 'review_url': '/paper/bloomberggpt-a-large-language-model-for/review/?hl=100783'}",,[],[]
86,15219,117042,87,phi-1.5-web 1.3B,{},phi-1.5-web 1.3B,,,,2023-09-11,{'Average (%)': '37.9'},{'Average (%)': 37.9},False,"{'id': 1275377, 'title': 'Textbooks Are All You Need II: phi-1.5 technical report', 'url': '/paper/textbooks-are-all-you-need-ii-phi-1-5', 'published': '2023-09-11T00:00:00.000000', 'code': True, 'review_url': '/paper/textbooks-are-all-you-need-ii-phi-1-5/review/?hl=117042'}",,[],[]
87,15219,117490,88,GPT-3 175B (0-shot),{},GPT-3 175B ,0-shot,,,2020-06-11,{'Average (%)': '37.7'},{'Average (%)': 37.7},False,"{'id': 216419, 'title': 'Measuring Massive Multitask Language Understanding', 'url': '/paper/measuring-massive-multitask-language', 'published': '2020-09-07T00:00:00.000000', 'code': True, 'review_url': '/paper/measuring-massive-multitask-language/review/?hl=117490'}",,[],[]
88,15219,100782,89,OPT 66B (5-shot),{},OPT 66B ,5-shot,,,2023-03-30,{'Average (%)': '36'},{'Average (%)': 36.0},False,"{'id': 1183339, 'title': 'BloombergGPT: A Large Language Model for Finance', 'url': '/paper/bloomberggpt-a-large-language-model-for', 'published': '2023-03-30T00:00:00.000000', 'code': False, 'review_url': '/paper/bloomberggpt-a-large-language-model-for/review/?hl=100782'}",,[],[]
89,15219,73128,90,Flan-T5-Base 250M,{},Flan-T5-Base 250M,,,,2022-10-20,{'Average (%)': '35.9'},{'Average (%)': 35.9},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=73128'}",,[],[]
90,15219,73153,91,Flan-T5-Base 250M (CoT),{},Flan-T5-Base 250M ,CoT,,,2022-10-20,{'Average (%)': '33.7'},{'Average (%)': 33.7},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=73153'}",,"[{'id': 184, 'name': 'fine-tuned', 'color': '#e56666'}]",[]
91,15219,47575,92,GPT-NeoX 20B (5-shot),{},GPT-NeoX 20B ,5-shot,,,2022-04-14,{'Average (%)': '33.6'},{'Average (%)': 33.6},False,"{'id': 994573, 'title': 'GPT-NeoX-20B: An Open-Source Autoregressive Language Model', 'url': '/paper/gpt-neox-20b-an-open-source-autoregressive-1', 'published': '2022-04-14T00:00:00.000000', 'code': True, 'review_url': None}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
92,15219,47495,93,GPT-2-XL 1.5B (fine-tuned),{},GPT-2-XL 1.5B ,fine-tuned,,,2019-11-05,{'Average (%)': '32.4'},{'Average (%)': 32.4},False,"{'id': 216419, 'title': 'Measuring Massive Multitask Language Understanding', 'url': '/paper/measuring-massive-multitask-language', 'published': '2020-09-07T00:00:00.000000', 'code': True, 'review_url': '/paper/measuring-massive-multitask-language/review/?hl=47495'}",,"[{'id': 184, 'name': 'fine-tuned', 'color': '#e56666'}]",[]
93,15219,118727,94,RWKV v5 Eagle 7B,{},RWKV v5 Eagle 7B,,,,2024-01-28,{'Average (%)': '31'},{'Average (%)': 31.0},False,"{'id': None, 'title': None, 'url': None, 'published': None, 'code': False, 'review_url': None}",,[],[]
94,15219,120435,95,LLaMA7B-MiLe-Loss(5-shot),{},LLaMA7B-MiLe-Loss,5-shot,,,2023-10-30,{'Average (%)': '29.68'},{'Average (%)': 29.68},True,"{'id': 1311580, 'title': 'MiLe Loss: a New Loss for Mitigating the Bias of Learning Difficulties in Generative Language Models', 'url': '/paper/infoentropy-loss-to-mitigate-bias-of-learning', 'published': '2023-10-30T00:00:00.000000', 'code': True, 'review_url': None}",,[],[]
95,15219,47502,96,Gopher 7.1B (5-shot),{},Gopher 7.1B ,5-shot,,,2021-12-08,{'Average (%)': '29.5'},{'Average (%)': 29.5},False,"{'id': 942590, 'title': 'Scaling Language Models: Methods, Analysis & Insights from Training Gopher', 'url': '/paper/scaling-language-models-methods-analysis-1', 'published': '2021-12-08T00:00:00.000000', 'code': True, 'review_url': None}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
96,15219,73127,97,Flan-T5-Small 80M,{},Flan-T5-Small 80M,,,,2022-10-20,{'Average (%)': '28.7'},{'Average (%)': 28.7},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=73127'}",,[],[]
97,15219,47556,98,GPT-NeoX 20B (0-shot),{},GPT-NeoX 20B ,0-shot,,,2022-04-14,{'Average (%)': '28.6'},{'Average (%)': 28.6},False,"{'id': 994573, 'title': 'GPT-NeoX-20B: An Open-Source Autoregressive Language Model', 'url': '/paper/gpt-neox-20b-an-open-source-autoregressive-1', 'published': '2022-04-14T00:00:00.000000', 'code': True, 'review_url': None}",,"[{'id': 188, 'name': 'zero-shot', 'color': '#2771D3'}]",[]
98,15219,114902,99,Falcon 7B (5-shot),{},Falcon 7B ,5-shot,,,2023-11-28,{'Average (%)': '28.0'},{'Average (%)': 28.0},False,"{'id': 1329402, 'title': 'The Falcon Series of Open Language Models', 'url': '/paper/the-falcon-series-of-open-language-models', 'published': '2023-11-28T00:00:00.000000', 'code': False, 'review_url': '/paper/the-falcon-series-of-open-language-models/review/?hl=114902'}",,[],[]
99,15219,47581,100,RoBERTa-base 125M (fine-tuned),{},RoBERTa-base 125M ,fine-tuned,,,2019-07-26,{'Average (%)': '27.9'},{'Average (%)': 27.9},False,"{'id': 148282, 'title': 'RoBERTa: A Robustly Optimized BERT Pretraining Approach', 'url': '/paper/roberta-a-robustly-optimized-bert-pretraining', 'published': '2019-07-26T00:00:00.000000', 'code': True, 'review_url': '/paper/roberta-a-robustly-optimized-bert-pretraining/review/?hl=47581'}",,"[{'id': 184, 'name': 'fine-tuned', 'color': '#e56666'}]",[]
100,15219,47501,101,Gopher 1.4B (5-shot),{},Gopher 1.4B ,5-shot,,,2021-12-08,{'Average (%)': '27.3'},{'Average (%)': 27.3},False,"{'id': 942590, 'title': 'Scaling Language Models: Methods, Analysis & Insights from Training Gopher', 'url': '/paper/scaling-language-models-methods-analysis-1', 'published': '2021-12-08T00:00:00.000000', 'code': True, 'review_url': None}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
101,15219,47555,102,GPT-J 6B (zero-shot),{},GPT-J 6B ,zero-shot,,,2021-05-01,{'Average (%)': '27.3'},{'Average (%)': 27.3},False,"{'id': 994573, 'title': 'GPT-NeoX-20B: An Open-Source Autoregressive Language Model', 'url': '/paper/gpt-neox-20b-an-open-source-autoregressive-1', 'published': '2022-04-14T00:00:00.000000', 'code': True, 'review_url': None}",,"[{'id': 188, 'name': 'zero-shot', 'color': '#2771D3'}]",[]
102,15219,47580,103,ALBERT-xxlarge 223M (fine-tuned),{},ALBERT-xxlarge 223M ,fine-tuned,,,2019-09-26,{'Average (%)': '27.1'},{'Average (%)': 27.1},False,"{'id': 156146, 'title': 'ALBERT: A Lite BERT for Self-supervised Learning of Language Representations', 'url': '/paper/albert-a-lite-bert-for-self-supervised', 'published': '2019-09-26T00:00:00.000000', 'code': True, 'review_url': '/paper/albert-a-lite-bert-for-self-supervised/review/?hl=47580'}",,"[{'id': 184, 'name': 'fine-tuned', 'color': '#e56666'}]",[]
103,15219,47577,104,GPT-3 13B (5-shot),{},GPT-3 13B ,5-shot,,,2020-06-11,{'Average (%)': '26'},{'Average (%)': 26.0},False,"{'id': 216419, 'title': 'Measuring Massive Multitask Language Understanding', 'url': '/paper/measuring-massive-multitask-language', 'published': '2020-09-07T00:00:00.000000', 'code': True, 'review_url': '/paper/measuring-massive-multitask-language/review/?hl=47577'}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
104,15219,118518,105,"GPT-3 13B (few-shot, k=32)",{},GPT-3 13B ,"few-shot, k=32",,,2020-05-28,{'Average (%)': '26'},{'Average (%)': 26.0},False,"{'id': 198147, 'title': 'Language Models are Few-Shot Learners', 'url': '/paper/language-models-are-few-shot-learners', 'published': '2020-05-28T00:00:00.000000', 'code': True, 'review_url': '/paper/language-models-are-few-shot-learners/review/?hl=118518'}",,[],[]
105,15219,47579,106,GPT-3 2.7B (5-shot),{},GPT-3 2.7B ,5-shot,,,2020-06-11,{'Average (%)': '25.9'},{'Average (%)': 25.9},False,"{'id': 216419, 'title': 'Measuring Massive Multitask Language Understanding', 'url': '/paper/measuring-massive-multitask-language', 'published': '2020-09-07T00:00:00.000000', 'code': True, 'review_url': '/paper/measuring-massive-multitask-language/review/?hl=47579'}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
106,15219,117949,107,GPT-3 2.7B (5-shot),{},GPT-3 2.7B ,5-shot,,,2020-05-28,{'Average (%)': '25.9'},{'Average (%)': 25.9},False,"{'id': 198147, 'title': 'Language Models are Few-Shot Learners', 'url': '/paper/language-models-are-few-shot-learners', 'published': '2020-05-28T00:00:00.000000', 'code': True, 'review_url': '/paper/language-models-are-few-shot-learners/review/?hl=117949'}",,[],[]
107,15219,47500,108,Gopher 0.4B (5-shot),{},Gopher 0.4B ,5-shot,,,2021-12-08,{'Average (%)': '25.7'},{'Average (%)': 25.7},False,"{'id': 942590, 'title': 'Scaling Language Models: Methods, Analysis & Insights from Training Gopher', 'url': '/paper/scaling-language-models-methods-analysis-1', 'published': '2021-12-08T00:00:00.000000', 'code': True, 'review_url': None}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
108,15219,47493,109,Random chance baseline,{},Random chance baseline,,,,2020-09-07,{'Average (%)': '25.0'},{'Average (%)': 25.0},False,"{'id': 216419, 'title': 'Measuring Massive Multitask Language Understanding', 'url': '/paper/measuring-massive-multitask-language', 'published': '2020-09-07T00:00:00.000000', 'code': True, 'review_url': '/paper/measuring-massive-multitask-language/review/?hl=47493'}",,[],[]
109,15219,47578,110,GPT-3 6.7B (5-shot),{},GPT-3 6.7B ,5-shot,,,2020-06-11,{'Average (%)': '24.9'},{'Average (%)': 24.9},False,"{'id': 216419, 'title': 'Measuring Massive Multitask Language Understanding', 'url': '/paper/measuring-massive-multitask-language', 'published': '2020-09-07T00:00:00.000000', 'code': True, 'review_url': '/paper/measuring-massive-multitask-language/review/?hl=47578'}",,"[{'id': 183, 'name': 'few-shot', 'color': '#a1df95'}]",[]
110,15219,117942,111,GPT-3 6.7B (5-shot),{},GPT-3 6.7B ,5-shot,,,2020-05-28,{'Average (%)': '24.9'},{'Average (%)': 24.9},False,"{'id': 198147, 'title': 'Language Models are Few-Shot Learners', 'url': '/paper/language-models-are-few-shot-learners', 'published': '2020-05-28T00:00:00.000000', 'code': True, 'review_url': '/paper/language-models-are-few-shot-learners/review/?hl=117942'}",,[],[]
111,15219,119856,112,Mixtral-8x7B-Instruct-v0.1,{},Mixtral-8x7B-Instruct-v0.1,,,,2020-09-07,{'Average (%)': '20.0'},{'Average (%)': 20.0},False,"{'id': 216419, 'title': 'Measuring Massive Multitask Language Understanding', 'url': '/paper/measuring-massive-multitask-language', 'published': '2020-09-07T00:00:00.000000', 'code': True, 'review_url': '/paper/measuring-massive-multitask-language/review/?hl=119856'}",,[],[]
112,15219,73152,113,Flan-T5-Small 80M (CoT),{},Flan-T5-Small 80M ,CoT,,,2022-10-20,{'Average (%)': '12.1'},{'Average (%)': 12.1},False,"{'id': 1097139, 'title': 'Scaling Instruction-Finetuned Language Models', 'url': '/paper/scaling-instruction-finetuned-language-models', 'published': '2022-10-20T00:00:00.000000', 'code': True, 'review_url': '/paper/scaling-instruction-finetuned-language-models/review/?hl=73152'}",,[],[]
